{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek-Shetty-02/DATABRICKS_PYSPARK/blob/main/SCENARIOS_01_TO_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsxMS8UNlfYl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56zZZZ7Ty-qn"
      },
      "source": [
        "# **SCENARIO 01**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t04CpkBTjGyB",
        "outputId": "631576ec-409a-4c67-bf36-a2a3cb9da3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+------+\n",
            "|Team_1|Team_2|Winner|\n",
            "+------+------+------+\n",
            "| India|    SL| India|\n",
            "|    SL|   Aus|   Aus|\n",
            "|    SA|   Eng|   Eng|\n",
            "|   Eng|    NZ|    NZ|\n",
            "|   Aus| India| India|\n",
            "+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"India\", \"SL\", \"India\"),\n",
        "    (\"SL\", \"Aus\", \"Aus\"),\n",
        "    (\"SA\", \"Eng\", \"Eng\"),\n",
        "    (\"Eng\", \"NZ\", \"NZ\"),\n",
        "    (\"Aus\", \"India\", \"India\"),\n",
        "]\n",
        "\n",
        "columns = [\"Team_1\", \"Team_2\", \"Winner\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBO5AZ9tv0Tw",
        "outputId": "2cd61213-8f8d-4b69-d8f8-a9eafd4b329d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------+----------+------------+\n",
            "|team_name|matches_played|no_of_wins|no_of_losses|\n",
            "+---------+--------------+----------+------------+\n",
            "|       SL|             2|         0|           2|\n",
            "|    India|             2|         2|           0|\n",
            "|      Eng|             2|         1|           1|\n",
            "|       SA|             1|         0|           1|\n",
            "|      Aus|             2|         1|           1|\n",
            "|       NZ|             1|         1|           0|\n",
            "+---------+--------------+----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1= df.select(\"Team_1\")\n",
        "df2= df.select(\"Team_2\")\n",
        "union_df = df1.unionAll(df2) \\\n",
        "              .groupBy('Team_1') \\\n",
        "              .agg(count(\"Team_1\").alias(\"matches_played\")) \\\n",
        "              .withColumnRenamed(\"Team_1\", 'team_name')\n",
        "# union_df.show()\n",
        "\n",
        "join_df = union_df.join(df, union_df.team_name == df.Winner, 'left') \\\n",
        "                  .drop(\"Team_1\", \"Team_2\")\n",
        "# join_df.show()\n",
        "\n",
        "results_df = join_df.groupBy(\"team_name\", \"matches_played\") \\\n",
        "                    .agg(count(\"Winner\").alias(\"no_of_wins\"))\n",
        "# results_df.show()\n",
        "\n",
        "final_df = results_df.withColumn(\"matches_played\", col(\"matches_played\").cast(IntegerType())) \\\n",
        "                      .withColumn(\"no_of_wins\", col(\"no_of_wins\").cast(IntegerType())) \\\n",
        "                      .withColumn(\"no_of_losses\", col(\"matches_played\") - col(\"no_of_wins\" ))\n",
        "final_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vhuAEkNvEsb"
      },
      "source": [
        "# **SCENARIO 02**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyG_5PjRvFZR",
        "outputId": "14de6ff5-8a3f-47bb-b204-148cd5e2d5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+------------+\n",
            "|employee_id|department_id|primary_flag|\n",
            "+-----------+-------------+------------+\n",
            "|          1|            1|           N|\n",
            "|          2|            1|           Y|\n",
            "|          2|            2|           N|\n",
            "|          3|            3|           N|\n",
            "|          4|            2|           N|\n",
            "|          4|            3|           Y|\n",
            "|          4|            4|           N|\n",
            "+-----------+-------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data2 = [\n",
        "    (1, 1, \"N\"),  # Y\n",
        "    (2, 1, \"Y\"),\n",
        "    (2, 2, \"N\"),\n",
        "    (3, 3, \"N\"),  # Y\n",
        "    (4, 2, \"N\"),\n",
        "    (4, 3, \"Y\"),\n",
        "    (4, 4, \"N\"),\n",
        "]\n",
        "\n",
        "columns = [\"employee_id\", \"department_id\", \"primary_flag\"]\n",
        "\n",
        "df = spark.createDataFrame(data2,columns)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-6OUvBYzar_",
        "outputId": "164eaa54-6e0a-435f-800f-40f4b336e680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+------------+\n",
            "|employee_id|department_id|primary_flag|\n",
            "+-----------+-------------+------------+\n",
            "|          3|            3|           N|\n",
            "|          1|            1|           N|\n",
            "|          4|            2|           N|\n",
            "|          2|            2|           N|\n",
            "|          4|            4|           N|\n",
            "|          2|            1|           Y|\n",
            "|          4|            3|           Y|\n",
            "+-----------+-------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# dff = df.filter(col(\"primary_flag\")== \"Y\")\\\n",
        "#         .select(\"employee_id\",\"department_id\")\n",
        "\n",
        "# dff.show()\n",
        "\n",
        "\n",
        "\n",
        "dff = df.orderBy(\"primary_flag\").show()\n",
        "\n",
        "\n",
        "# window = window.partitionBy(\"employee_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcWlEeRFzbYF"
      },
      "source": [
        "# **SCENARIO 03**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgAMzw36vk6E",
        "outputId": "28049300-6e6e-4faf-9c06-665a701e0461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|customer_name          |\n",
            "+-----------------------+\n",
            "|kasireddy naidu        |\n",
            "|konidela ram charan    |\n",
            "|Nandamuri tarak ramarao|\n",
            "|charan                 |\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data3 = [\n",
        "    (\"kasireddy naidu\",),\n",
        "    (\"konidela ram charan\",),\n",
        "    (\"Nandamuri tarak ramarao\",),\n",
        "    (\"charan\",),\n",
        "]\n",
        "\n",
        "columns = [\"customer_name\"]\n",
        "\n",
        "df3 = spark.createDataFrame(data3,columns)\n",
        "\n",
        "df3.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCU10numvqeZ",
        "outputId": "5fca318f-e233-4f6c-a07f-0713bde77027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+----------+-----------+---------+\n",
            "|customer_name              |First_name|Middle_name|Last_name|\n",
            "+---------------------------+----------+-----------+---------+\n",
            "|[kasireddy, naidu]         |Kasireddy |Naidu      |NULL     |\n",
            "|[konidela, ram, charan]    |Konidela  |Ram        |Charan   |\n",
            "|[Nandamuri, tarak, ramarao]|Nandamuri |Tarak      |Ramarao  |\n",
            "|[charan]                   |Charan    |NULL       |NULL     |\n",
            "+---------------------------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "split_df = df3.withColumn(\"customer_name\",split(col(\"customer_name\"),\" \"))\n",
        "\n",
        "\n",
        "df_final = split_df.withColumn(\"First_name\",when(size(col(\"customer_name\")) >= 1,initcap(col(\"customer_name\").getItem(0))))\\\n",
        "                   .withColumn(\"Middle_name\",when(size(col(\"customer_name\")) >= 2,initcap(col(\"customer_name\").getItem(1))))\\\n",
        "                   .withColumn(\"Last_name\",when(size(col(\"customer_name\")) >= 3,initcap(concat_ws(\" \", slice(col(\"customer_name\"), 3, 10)))))\n",
        "\n",
        "df_final.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxsiNSb8vrEr"
      },
      "source": [
        "# **BONUS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9LsT7QWvrvl",
        "outputId": "b804f12d-6de4-4dff-ace8-5ea777f07dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------+\n",
            "|customer_name                |\n",
            "+-----------------------------+\n",
            "|kasireddy naidu              |\n",
            "|konidela ram charan          |\n",
            "|nandamuri tarak ramarao      |\n",
            "|charan                       |\n",
            "|megastar chiranjeevi konidela|\n",
            "|allu arjun stylish star      |\n",
            "|pawan kalyan power star      |\n",
            "|jr ntr young tiger           |\n",
            "|mahesh babu superstar        |\n",
            "|prabhas rebel pan india star |\n",
            "+-----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data4 = [\n",
        "    (\"kasireddy naidu\",),\n",
        "    (\"konidela ram charan\",),\n",
        "    (\"nandamuri tarak ramarao\",),\n",
        "    (\"charan\",),\n",
        "    (\"megastar chiranjeevi konidela\",),\n",
        "    (\"allu arjun stylish star\",),\n",
        "    (\"pawan kalyan power star\",),\n",
        "    (\"jr ntr young tiger\",),\n",
        "    (\"mahesh babu superstar\",),\n",
        "    (\"prabhas rebel pan india star\",),\n",
        "]\n",
        "\n",
        "columns4 = [\"customer_name\"]\n",
        "\n",
        "df4 = spark.createDataFrame(data4,columns4)\n",
        "\n",
        "df4.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAdrkKeRwmK_",
        "outputId": "a2fe9d59-39ff-4db0-ae44-312d762a366d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------+----------+-----------+--------------+\n",
            "|customer_name                     |First_name|Middle_name|Last_name     |\n",
            "+----------------------------------+----------+-----------+--------------+\n",
            "|[kasireddy, naidu]                |Kasireddy |NULL       |NULL          |\n",
            "|[konidela, ram, charan]           |Konidela  |Ram        |Charan        |\n",
            "|[nandamuri, tarak, ramarao]       |Nandamuri |Tarak      |Ramarao       |\n",
            "|[charan]                          |Charan    |NULL       |NULL          |\n",
            "|[megastar, chiranjeevi, konidela] |Megastar  |Chiranjeevi|Konidela      |\n",
            "|[allu, arjun, stylish, star]      |Allu      |Arjun      |Stylish Star  |\n",
            "|[pawan, kalyan, power, star]      |Pawan     |Kalyan     |Power Star    |\n",
            "|[jr, ntr, young, tiger]           |Jr        |Ntr        |Young Tiger   |\n",
            "|[mahesh, babu, superstar]         |Mahesh    |Babu       |Superstar     |\n",
            "|[prabhas, rebel, pan, india, star]|Prabhas   |Rebel      |Pan India Star|\n",
            "+----------------------------------+----------+-----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from posix import truncate\n",
        "s_df = df4.withColumn(\"customer_name\",split(col(\"customer_name\"),\" \"))\n",
        "\n",
        "\n",
        "df_fin = s_df.withColumn(\"First_name\",when(size(col(\"customer_name\")) >= 1,initcap(col(\"customer_name\").getItem(0))))\\\n",
        "                   .withColumn(\"Middle_name\",when(size(col(\"customer_name\")) >= 3,initcap(col(\"customer_name\").getItem(1))))\\\n",
        "                   .withColumn(\"Last_name\",when(size(col(\"customer_name\")) >=3,initcap(concat_ws(\" \", slice(col(\"customer_name\"), 3, 10)))))\n",
        "\n",
        "df_fin.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXqnpQydwmHm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KAimCNSwm5a"
      },
      "source": [
        "# **SCENARIO 04**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLlnu2y4wnYa",
        "outputId": "67bcbd96-c284-4f94-a0cb-d685ae16b67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-------+------+----------+\n",
            "|t_id|user_id|amount|    t_date|\n",
            "+----+-------+------+----------+\n",
            "|   1|    101| 500.0|2024-01-01|\n",
            "|   1|    101| 600.0|2024-01-01|\n",
            "|   2|    102| 200.0|2024-01-02|\n",
            "|   3|    101| 300.0|2024-01-03|\n",
            "|   4|    103| 100.0|2024-01-04|\n",
            "|   5|    102| 400.0|2024-01-05|\n",
            "|   6|    103| 600.0|2024-01-06|\n",
            "|   7|    101| 200.0|2024-01-07|\n",
            "+----+-------+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data5 = [\n",
        "    (1, 101, 500.0, \"2024-01-01\"),\n",
        "    (1, 101, 600.0, \"2024-01-01\"),\n",
        "    (2, 102, 200.0, \"2024-01-02\"),\n",
        "    (3, 101, 300.0, \"2024-01-03\"),\n",
        "    (4, 103, 100.0, \"2024-01-04\"),\n",
        "    (5, 102, 400.0, \"2024-01-05\"),\n",
        "    (6, 103, 600.0, \"2024-01-06\"),\n",
        "    (7, 101, 200.0, \"2024-01-07\"),\n",
        "]\n",
        "\n",
        "columns5 = [\"t_id\", \"user_id\", \"amount\", \"t_date\"]\n",
        "\n",
        "df5 = spark.createDataFrame(data5,columns5)\n",
        "\n",
        "df5.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE1lUM4eyo8S",
        "outputId": "f6ae2d1f-fe46-4677-d111-0c504d5d2547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----------+\n",
            "|user_id|total_spent|\n",
            "+-------+-----------+\n",
            "|    101|     1600.0|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "agg_df = df5.filter(col(\"user_id\")==101).groupBy(\"user_id\").agg(sum(\"amount\").alias(\"total_spent\"))\n",
        "\n",
        "agg_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozFH_n4_ypsG"
      },
      "source": [
        "# **SCENARIO 05**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4MqGHGdyqPf",
        "outputId": "24ede166-b41f-4c62-c1ec-efa617f669ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+\n",
            "|team|\n",
            "+----+\n",
            "| RCB|\n",
            "| CSK|\n",
            "|  MI|\n",
            "|PBKS|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data6 = [\n",
        "    (\"RCB\",),\n",
        "    (\"CSK\",),\n",
        "    (\"MI\",),\n",
        "    (\"PBKS\",),\n",
        "]\n",
        "\n",
        "columns6 = [\"team\"]\n",
        "\n",
        "df = spark.createDataFrame(data6,columns6)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlL1wkGRpF-e",
        "outputId": "44afbf0f-e463-4f59-e4cb-a58f01e4c99e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|team1|team2|\n",
            "+-----+-----+\n",
            "|  CSK|  RCB|\n",
            "|  CSK|   MI|\n",
            "|  CSK| PBKS|\n",
            "|   MI|  RCB|\n",
            "| PBKS|  RCB|\n",
            "|   MI| PBKS|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# two teams: two tables\n",
        "\n",
        "df1 = df.alias(\"df1\")\n",
        "df2 = df.alias(\"df2\")\n",
        "\n",
        "matchs = df1.join(df2, col(\"df1.team\") < col(\"df2.team\")) \\\n",
        "              .select(col(\"df1.team\").alias(\"team1\"), col(\"df2.team\").alias(\"team2\"))\n",
        "\n",
        "matchs.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvFKSv109i24Mlkl34zksJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}